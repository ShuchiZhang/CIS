{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Defense framework against adversarial attack"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import os.path\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "import scipy\n",
    "from scipy.sparse import vstack\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>url</th>\n",
       "      <th>Label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>99995</th>\n",
       "      <td>http://allgxrltogaparty.co.uk/gallery2/maxn.ph...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99996</th>\n",
       "      <td>http://3401.e-prxntphoto.co.uk/thxsxsessex/xnd...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99997</th>\n",
       "      <td>http://acard4u.co.uk/product_xnfo.php?cPath=10...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99998</th>\n",
       "      <td>http://aboutscotland.co.uk/ecosse/portessxe/xn...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99999</th>\n",
       "      <td>http://allxanceleague.co.uk/cgx-bxn/phpBB2/vxe...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                     url  Label\n",
       "99995  http://allgxrltogaparty.co.uk/gallery2/maxn.ph...      4\n",
       "99996  http://3401.e-prxntphoto.co.uk/thxsxsessex/xnd...      4\n",
       "99997  http://acard4u.co.uk/product_xnfo.php?cPath=10...      4\n",
       "99998  http://aboutscotland.co.uk/ecosse/portessxe/xn...      4\n",
       "99999  http://allxanceleague.co.uk/cgx-bxn/phpBB2/vxe...      4"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Reading data from csv file\n",
    "data = pd.read_csv(\"FinalDataIX.csv\")\n",
    "data.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Two colums are in the dataset. First column contains all urls and the second column is the label of these urls: 0 represents benign URLs, 1 represents defacement sites URLs, 2 represents malware URLs, 3 represents phishing URLs and 4 are spam URLs.\n",
    "\n",
    "The first half of datasets are inital URL datasets. The remaining half are datasets after adversarial attack."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    http://1337x.to/torrent/1048648/American-Snipe...\n",
       "1    http://1337x.to/torrent/1110018/Blackhat-2015-...\n",
       "2    http://1337x.to/torrent/1122940/Blackhat-2015-...\n",
       "3    http://1337x.to/torrent/1124395/Fast-and-Furio...\n",
       "4    http://1337x.to/torrent/1145504/Avengers-Age-o...\n",
       "Name: url, dtype: object"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Labels\n",
    "y = data[\"Label\"]\n",
    "\n",
    "# Features\n",
    "url_list = data[\"url\"]\n",
    "\n",
    "url_list.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TF-IDF is used to tokenize our URLs. it is used by detecting the frequency of a specific word in the artcle. By applying TF-IDF to our URLs, we can extract information and feed the data we get into our model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using Tokenizer\n",
    "vectorizer = TfidfVectorizer()\n",
    "\n",
    "# Store vectors into X variable as Our XFeatures\n",
    "X = vectorizer.fit_transform(url_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We need to have the first half of our dataset to train our initial model and verify its correctness.So the first 50000 URLs and its labels are stored in X_initial and y_initial separately."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_initial = X[0]\n",
    "for i in range(49999):\n",
    "    ele = X[i + 1]\n",
    "    X_initial = vstack((X_initial, ele))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_initial = []\n",
    "for i in range(50000):\n",
    "    y_initial.append(y[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Split test and train datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split into training and testing dataset 80:20 ratio\n",
    "X_initial_train, X_initial_test, y_initial_train, y_initial_test = train_test_split(X_initial, y_initial, test_size=0.1, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train the initial model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\samzhang\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:764: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression()"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Model Building using logistic regression\n",
    "logit_initial = LogisticRegression()\n",
    "logit_initial.fit(X_initial_train, y_initial_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test the accuracy of initial model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of our model is:  0.99\n"
     ]
    }
   ],
   "source": [
    "# Accuracy of Our Model\n",
    "print(\"Accuracy of our model is: \",logit_initial.score(X_initial_test, y_initial_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get the dataset after applying adversarial attack and store its url in X_attack."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_attack = X[50000]\n",
    "for i in range(50000,99999):\n",
    "    ele = X[i + 1]\n",
    "    X_attack = vstack((X_attack, ele))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_attack = y_initial"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Show the accuracy of our model after attack. The confidence should be less than 90% and otherwise it is not a successful attack."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of our model is:  0.9127\n"
     ]
    }
   ],
   "source": [
    "print(\"Accuracy of our model is: \",logit_initial.score(X_attack, y_attack))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reverse URL Method"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Defines the method to reverse the URL."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reverseString(s):\n",
    " if s == \"\":\n",
    "     return s\n",
    " else:\n",
    "     return reverseString(s[1:])+s[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Combins the reversed url with initial one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "url_list_reverse = []\n",
    "for i in range(len(url_list)):\n",
    "    url_list_reverse.append(url_list[i] + reverseString(url_list[i]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tokenize URLs, extract attacking datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using Tokenizer\n",
    "vectorizer = TfidfVectorizer()\n",
    "\n",
    "# Store vectors into X variable as Our XFeatures\n",
    "X_reverse = vectorizer.fit_transform(url_list_reverse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_reverse_ini = X_reverse[0]\n",
    "for i in range(49999):\n",
    "    ele = X_reverse[i + 1]\n",
    "    X_reverse_ini = vstack((X_reverse_ini, ele))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_reverse_ini = y_initial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_reverse_attack = X_reverse[50000]\n",
    "for i in range(50000,99999):\n",
    "    ele = X_reverse[i + 1]\n",
    "    X_reverse_attack = vstack((X_reverse_attack, ele))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_reverse_attack = y_initial"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\samzhang\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:764: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression()"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Model Building using logistic regression\n",
    "logit_reverse = LogisticRegression()\n",
    "logit_reverse.fit(X_reverse_ini, y_reverse_ini)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Show the accuracy under weak defense."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of our model is:  0.93936\n"
     ]
    }
   ],
   "source": [
    "print(\"Accuracy of our model is: \",logit_reverse.score(X_reverse_attack, y_reverse_attack))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Information extraction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Extract key information and trim irrelevant information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "url_list_key = []\n",
    "for i in range(len(url_list)):\n",
    "    url_list_key.append(url_list[i].replace(\"http://\",'').replace(\"https://\",''))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tokenize the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using Tokenizer\n",
    "vectorizer = TfidfVectorizer()\n",
    "\n",
    "# Store vectors into X variable as Our XFeatures\n",
    "X_key = vectorizer.fit_transform(url_list_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_key_ini = X_key[0]\n",
    "for i in range(49999):\n",
    "    ele = X_key[i + 1]\n",
    "    X_key_ini = vstack((X_key_ini, ele))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_key_ini = y_initial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_key_attack = X_key[50000]\n",
    "for i in range(50000,99999):\n",
    "    ele = X_key[i + 1]\n",
    "    X_key_attack = vstack((X_key_attack, ele))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_key_attack = y_initial"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\samzhang\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:764: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression()"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Model Building using logistic regression\n",
    "logit_key = LogisticRegression()\n",
    "logit_key.fit(X_key_ini, y_key_ini)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Show accuracy after extracting key information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of our model is:  0.91092\n"
     ]
    }
   ],
   "source": [
    "print(\"Accuracy of our model is: \",logit_key.score(X_key_attack, y_key_attack))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Assemble weak defenses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "InfoEx [1]\n",
      "Reverse [1]\n"
     ]
    }
   ],
   "source": [
    "print(\"InfoEx\",logit.predict(X_key_a[100000]))\n",
    "      \n",
    "print(\"Reverse\",logit.predict(X_key_a[100000]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Defense framework against adversarial attack"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import os.path\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "import scipy\n",
    "from scipy.sparse import vstack\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>url</th>\n",
       "      <th>Label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>99995</th>\n",
       "      <td>http://allgorltogaparty.co.ik/gallery2/maon.ph...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99996</th>\n",
       "      <td>http://3401.e-prontphoto.co.ik/thososessex/ond...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99997</th>\n",
       "      <td>http://acard4i.co.ik/prodict_onfo.php?cPath=10...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99998</th>\n",
       "      <td>http://aboitscotland.co.ik/ecosse/portessoe/on...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99999</th>\n",
       "      <td>http://alloanceleagie.co.ik/cgo-bon/phpBB2/voe...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                     url  Label\n",
       "99995  http://allgorltogaparty.co.ik/gallery2/maon.ph...      4\n",
       "99996  http://3401.e-prontphoto.co.ik/thososessex/ond...      4\n",
       "99997  http://acard4i.co.ik/prodict_onfo.php?cPath=10...      4\n",
       "99998  http://aboitscotland.co.ik/ecosse/portessoe/on...      4\n",
       "99999  http://alloanceleagie.co.ik/cgo-bon/phpBB2/voe...      4"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Reading data from csv file\n",
    "data = pd.read_csv(\"FinalDataIni.csv\")\n",
    "data.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Two colums are in the dataset. First column contains all urls and the second column is the label of these urls: 0 represents benign URLs, 1 represents defacement sites URLs, 2 represents malware URLs, 3 represents phishing URLs and 4 are spam URLs.\n",
    "\n",
    "The first half of datasets are inital URL datasets. The remaining half are datasets after adversarial attack."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    http://1337x.to/torrent/1048648/American-Snipe...\n",
       "1    http://1337x.to/torrent/1110018/Blackhat-2015-...\n",
       "2    http://1337x.to/torrent/1122940/Blackhat-2015-...\n",
       "3    http://1337x.to/torrent/1124395/Fast-and-Furio...\n",
       "4    http://1337x.to/torrent/1145504/Avengers-Age-o...\n",
       "Name: url, dtype: object"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Labels\n",
    "y = data[\"Label\"]\n",
    "\n",
    "# Features\n",
    "url_list = data[\"url\"]\n",
    "\n",
    "url_list.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TF-IDF is used to tokenize our URLs. it is used by detecting the frequency of a specific word in the artcle. By applying TF-IDF to our URLs, we can extract information and feed the data we get into our model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<100000x73974 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 1285179 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Using Tokenizer\n",
    "vectorizer = TfidfVectorizer()\n",
    "\n",
    "# Store vectors into X variable as Our XFeatures\n",
    "X = vectorizer.fit_transform(url_list)\n",
    "\n",
    "X"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We need to have the first half of our dataset to train our initial model and verify its correctness.So the first 50000 URLs and its labels are stored in X_initial and y_initial separately."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_initial = X[0]\n",
    "for i in range(49999):\n",
    "    ele = X[i + 1]\n",
    "    X_initial = vstack((X_initial, ele))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_initial = []\n",
    "for i in range(50000):\n",
    "    y_initial.append(y[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Split test and train datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split into training and testing dataset 80:20 ratio\n",
    "X_initial_train, X_initial_test, y_initial_train, y_initial_test = train_test_split(X_initial, y_initial, test_size=0.1, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train the initial model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\samzhang\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:764: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression()"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Model Building using logistic regression\n",
    "logit_initial = LogisticRegression()\n",
    "logit_initial.fit(X_initial_train, y_initial_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test the accuracy of initial model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of our model is:  0.9896\n"
     ]
    }
   ],
   "source": [
    "# Accuracy of Our Model\n",
    "print(\"Accuracy of our model is: \",logit_initial.score(X_initial_test, y_initial_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get the dataset after applying adversarial attack and store its url in X_attack."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_attack = X[50000]\n",
    "for i in range(50000,99999):\n",
    "    ele = X[i + 1]\n",
    "    X_attack = vstack((X_attack, ele))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_attack = y_initial"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Show the accuracy of our model after attack. The confidence should be less than 90% and otherwise it is not a successful attack."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of our model with dataset of adversarial attack is:  0.79938\n"
     ]
    }
   ],
   "source": [
    "print(\"Accuracy of our model with dataset of adversarial attack is: \",logit_initial.score(X_attack, y_attack))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reverse URL Method"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Defines the method to reverse the URL."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reverseString(s):\n",
    " if s == \"\":\n",
    "     return s\n",
    " else:\n",
    "     return reverseString(s[1:])+s[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Combins the reversed url with initial one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "url_list_reverse = []\n",
    "for i in range(len(url_list)):\n",
    "    url_list_reverse.append(url_list[i] + reverseString(url_list[i]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tokenize URLs, extract attacking datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using Tokenizer\n",
    "vectorizer = TfidfVectorizer()\n",
    "\n",
    "# Store vectors into X variable as Our XFeatures\n",
    "X_reverse = vectorizer.fit_transform(url_list_reverse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_reverse_ini = X_reverse[0]\n",
    "for i in range(49999):\n",
    "    ele = X_reverse[i + 1]\n",
    "    X_reverse_ini = vstack((X_reverse_ini, ele))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_reverse_ini = y_initial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_reverse_attack = X_reverse[50000]\n",
    "for i in range(50000,99999):\n",
    "    ele = X_reverse[i + 1]\n",
    "    X_reverse_attack = vstack((X_reverse_attack, ele))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_reverse_attack = y_initial"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\samzhang\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:764: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression()"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Model Building using logistic regression\n",
    "logit_reverse = LogisticRegression()\n",
    "logit_reverse.fit(X_reverse_ini, y_reverse_ini)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Show the accuracy under weak defense."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of our model using reverse URL is:  0.84316\n"
     ]
    }
   ],
   "source": [
    "print(\"Accuracy of our model using reverse URL is: \",logit_reverse.score(X_reverse_attack, y_reverse_attack))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Information Extraction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Extract key information and trim irrelevant information such as \"http\", \"https\" and \".com\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "url_list_key = []\n",
    "for i in range(len(url_list)):\n",
    "    url_list_key.append(url_list[i].replace(\"https\",'').replace(\"http\",'').replace(\".com\",''))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tokenize the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using Tokenizer\n",
    "vectorizer = TfidfVectorizer()\n",
    "\n",
    "# Store vectors into X variable as Our XFeatures\n",
    "X_key = vectorizer.fit_transform(url_list_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_key_ini = X_key[0]\n",
    "for i in range(49999):\n",
    "    ele = X_key[i + 1]\n",
    "    X_key_ini = vstack((X_key_ini, ele))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_key_ini = y_initial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_key_attack = X_key[50000]\n",
    "for i in range(50000,99999):\n",
    "    ele = X_key[i + 1]\n",
    "    X_key_attack = vstack((X_key_attack, ele))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_key_attack = y_initial"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\samzhang\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:764: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression()"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Model Building using logistic regression\n",
    "logit_key = LogisticRegression()\n",
    "logit_key.fit(X_key_ini, y_key_ini)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Show accuracy after extracting key information. The accuracy is not promising and will not be used in the final framework."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of our model is:  0.78534\n"
     ]
    }
   ],
   "source": [
    "print(\"Accuracy of our model is: \",logit_key.score(X_key_attack, y_key_attack))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Perturbation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Change some characters in the initial dataset and dataset after adversarial attack."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "url_list_per = []\n",
    "for i in range(len(url_list)):\n",
    "    url_list_per.append(url_list[i].replace(\"i\",'u'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tokenize data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using Tokenizer\n",
    "vectorizer = TfidfVectorizer()\n",
    "\n",
    "# Store vectors into X variable as Our XFeatures\n",
    "X_per = vectorizer.fit_transform(url_list_per)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_per_ini = X_per[0]\n",
    "for i in range(49999):\n",
    "    ele = X_per[i + 1]\n",
    "    X_per_ini = vstack((X_per_ini, ele))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_per_ini = y_initial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_per_attack = X_per[50000]\n",
    "for i in range(50000,99999):\n",
    "    ele = X_per[i + 1]\n",
    "    X_per_attack = vstack((X_per_attack, ele))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_per_attack = y_initial"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train the model using logistic regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\samzhang\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:764: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression()"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Model Building using logistic regression\n",
    "logit_per = LogisticRegression()\n",
    "logit_per.fit(X_per_ini, y_per_ini)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The accuracy increases and the method might be applicable so will be accepted in the final framework"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of our model is:  0.91164\n"
     ]
    }
   ],
   "source": [
    "print(\"Accuracy of our model is: \",logit_per.score(X_per_attack, y_per_attack))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gan"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Uses the generator of GAN to alter our dataset and store them in another file \"FinalDataGan.csv\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reading data from csv file\n",
    "data_gan = pd.read_csv(\"FinalDataGan.csv\")\n",
    "\n",
    "# Features\n",
    "url_gan = data_gan[\"url\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using Tokenizer\n",
    "vectorizer = TfidfVectorizer()\n",
    "\n",
    "# Store vectors into X variable as Our XFeatures\n",
    "X_gan = vectorizer.fit_transform(url_gan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_gan_ini = X_gan[0]\n",
    "for i in range(49999):\n",
    "    ele = X_gan[i + 1]\n",
    "    X_gan_ini = vstack((X_gan_ini, ele))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_gan_ini = y_initial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_gan_attack = X_gan[50000]\n",
    "for i in range(50000,99999):\n",
    "    ele = X_gan[i + 1]\n",
    "    X_gan_attack = vstack((X_gan_attack, ele))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_gan_attack = y_initial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\samzhang\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:764: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression()"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Model Building using logistic regression\n",
    "logit_gan = LogisticRegression()\n",
    "logit_gan.fit(X_gan_ini, y_gan_ini)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of our model using GAN is:  0.8531\n"
     ]
    }
   ],
   "source": [
    "print(\"Accuracy of our model using GAN is: \",logit_gan.score(X_gan_attack, y_gan_attack))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Assemble weak defenses"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Uses each weak defense to predict separately first and use voting to decide final result. Store these result in a list \"result\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = []\n",
    "for i in range(49999):\n",
    "    result_count = [0,0,0,0,0]\n",
    "    key_result = logit_key.predict(X_key_attack[i])[0]\n",
    "    result_count[key_result] += 1\n",
    "    gan_result = logit_gan.predict(X_gan_attack[i])[0]\n",
    "    result_count[gan_result] += 1\n",
    "    per_result = logit_per.predict(X_per_attack[i])[0]\n",
    "    result_count[per_result] += 1\n",
    "    temp = max(result_count)\n",
    "    for j in range(5):\n",
    "        if temp == result_count[j]:\n",
    "            result.append(j)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compare the result got with initial label."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "success = 0\n",
    "for i in range(49999):\n",
    "    if result[i] == y_initial[i]:\n",
    "        success += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The final accuaracy increases to 85.61%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8560771215424309"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "success/49999"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
